<html>
	<head>
		<title>Hold for export</title>
		<link rel="stylesheet" type="text/css" href="/admin/css/jquery-ui-1.8.6.custom.css" />
		<link rel="stylesheet" type="text/css" href="/admin/css/jquery-ui-opencast-admin/jquery-ui-opencast-admin.css" />   
		<link rel="stylesheet" type="text/css" href="/admin/css/admin.css">
		<script type="text/javascript" src="/admin/jquery/jquery-1.4.4.min.js"></script>
		<script type="text/javascript" src="/admin/jquery/jquery-ui-1.8.9.custom.min.js"></script>    
		<script type="text/javascript" src="/admin/js/oc.utils.js"></script>
    	<script type="text/javascript" src="/admin/trimpath/trimpath-template-1.0.38.js"></script>
<script type="text/javascript">
	
	// Used to get the workflow id of the current operation that is executing.
	var postData = {
		'id': parent.document.getElementById("holdWorkflowId").value
	};
	
	
	var templateFrames = '{for f in frames}' +
                                '<div ' +
                                    'id="${f.id}" ' +
                                    'class="source-frame" ' +
                                    'style="width:100%; height:20%; background-color: blue;" ' +
                                 '>' +
                                  '<span id="${f.id}_width" style="display: none">${f.width}</span>' +
                                  '<span id="${f.id}_height" style="display: none">${f.height}</span>' +
                                '</div><p></p>' +
                              '{/for}';
	// Used when the user wants to try and determine the source video type automatically.
    var vgaDecodebin = "decodebin2 name=VgaDecodeBin";
    var cameraDecodebin = "decodebin2 name=CameraDecodeBin";
    // Used to decode MPEG 2 Program Stream video sources (like capture agent media.)
    var vgaMpegPS = "mpegpsdemux name=VgaPSDemux ! mpeg2dec name=VgaMpeg2Dec";
    var cameraMpegPS = "mpegpsdemux name=CameraPSDemux ! mpeg2dec name=CameraMpeg2Dec";
    // Used to decode MPEG 2 Transport Stream video sources. 
    var vgaMpegTS = "mpegtsdemux name=VgaTSDemux ! mpeg2dec name=VgaMpeg2Dec";
    var cameraMpegTS = "mpegtsdemux name=CameraTSDemux ! mpeg2dec name=CameraMpeg2Dec";
    // Used to decode x264 and H.264 AVC video sources inside an mp4 or mov container.  
    var vgaMp4x264 = "qtdemux name=VgaQTDemux ! ffdec_h264 name=VgaH264Dec";
    var cameraMp4x264 = "qtdemux name=CameraQTDemux ! ffdec_h264 name=CameraH264Dec";
    
    // This template is used when the media package has Camera, VGA and Audio sources and the user wants all three. 
    var cameraScreenAudioTemplate = "filesrc location=VGA ! VgaDECODE ! videorate ! video/x-raw-yuv,framerate=\(fraction\)30/1 ! " +
	"videobox border-alpha=1 top=0 bottom=0 left=-CameraWIDTH ! " +
	"videomixer name=mix sink_0::alpha=1 sink_1::alpha=1 background=black ! " +
	"VIDEOSCALE" + 
	"ffmpegcolorspace ! x264enc pass=5 quantizer=25 speed-preset=6 profile=3 ! queue name=camera ! mp4mux name=mux ! filesink location=OUTPUTFILE " +
	"filesrc location=CAMERA ! CameraDECODE ! videorate ! video/x-raw-yuv,framerate=\(fraction\)30/1 ! mix. " +
	"filesrc location=AUDIO ! decodebin2 name=AudioDecodeBin ! audioconvert ! audio/x-raw-int,rate=44100,channels=2 ! faac bitrate=160000 profile=2 ! queue name=audio ! mux."
    
	// This template is used when the user only wants VGA and Audio sources or that is all the media package has. 
	var screenAudioTemplate = "filesrc location=VGA ! VgaDECODE ! videorate ! video/x-raw-yuv,framerate=\(fraction\)30/1 ! " +
		"VIDEOSCALE" + 
		"ffmpegcolorspace ! x264enc pass=5 quantizer=25 speed-preset=6 profile=3 ! queue name=camera ! mp4mux name=mux ! filesink location=OUTPUTFILE " +
		"filesrc location=AUDIO ! decodebin2 name=AudioDecodeBin ! audioconvert ! audio/x-raw-int,rate=44100,channels=2 ! faac bitrate=160000 profile=2 ! queue name=audio ! mux."
    
	// If the user wants the original video source size for editing this is the choice. 
	var original = "";
    // If this video is going to end up on a mobile platform it needs to be scaled smaller for older mobiles. 
    var mobile = "videoscale ! video/x-raw-yuv,width=640,height=480 ! ";
    // If the video will end up on tablets then this will scale it appropriately saving video size even if it can handle more.
    var tablet = "videoscale ! video/x-raw-yuv,width=1024,height=768 ! ";
    // This will scale the video output to 720p. 
    var hd = "videoscale ! video/x-raw-yuv,width=1280,height=720 ! ";
    // This will scale the video output to 1080p. 
    var fullhd = "videoscale ! video/x-raw-yuv,width=1920,height=1080 ! ";
	
    // The temporary output file location. 
    var outputFile = "";
    // The replacement variable for the presentation or VGA source. 
	var presentation = "";
    // The replacement variable for the presenter or Camera source. 
	var presenter = "";
    // The width of the camera source in case to slide it in beside the VGA source in case both are used. 
	var presenterWidth = "";
    // The replacement variable for the audio source. 
	var audio = "";
    // The title of this media package. 
	var title = "";
    // The workflow id of this workflow operation. 
	var id = "";
	
	$(document).ready(function() {
		id = postData.id;             
		
        // load preview player and metadata
		$.ajax({
			url: '/workflow/instance/' + id + '.json',
			dataType: 'json', // or XML..
			success: function(data) {
				var tracks = data.workflow.mediapackage.media.track;
				if (!$.isArray(tracks)) {
					tracks = [tracks];
	            }
	
				var frames = [];
				for (var i = 0; i < tracks.length; i++) {
					var track = tracks[i];
					if (track.type.indexOf("/source") != -1 && track.video != undefined) {
						frames.push({id: track.id, width: track.video.resolution.split("x")[0], height: track.video.resolution.split("x")[1]});
					}
				}
	            var sources = {frames: frames};
	            processedTemplateData = templateFrames.process(sources);
	            $("#source-frames").html(processedTemplateData);
	            $(".source-frame").draggable({
					containment: $("#holdStateUI"),
					stack: ".source-frame",
					revert: 'invalid'
	            });
				$(".droppable-area").droppable({
					accept: '.source-frame',
					tolerance: 'fit'
				});
			}
		});
        
	
		// Determine the substitution variables for the Camera, VGA and Audio tracks from the media package.
		$.ajax({
			url: '/workflow/instance/' + id + '.json',
			dataType: 'json', // or XML..
			success: function(data) {
				title = data.workflow.mediapackage.title;
				var tracks = data.workflow.mediapackage.media.track;
				if (!$.isArray(tracks)) {
					tracks = [tracks];
				}
	
				var frames = [];
				for (var i = 0; i < tracks.length; i++) {
					var track = tracks[i];
					// Find presenter track. 
					if (track.type.indexOf("presenter/source") != -1 && track.video != undefined) {
						presenter = "${.vars[\"" + track.id + "\"]}";
						presenterWidth = track.video.resolution.split("x")[0];
					} 
					// Find presentation track. 
					else if (track.type.indexOf("presentation/source") != -1 && track.video != undefined) {
						presentation = "${.vars[\"" + track.id + "\"]}";
					} 
					// Find audio. 
					else if (track.type.indexOf("/source") != -1 && track.audio != undefined) {
						audio = "${.vars[\"" + track.id + "\"]}";
					}
				}
				updateTemplate();
			}
		});
		
		
		
		$("input:radio").click(function(){
			updateTemplate();
		});
	});
    
	/** Creates a gstreamer command based on radio buttons that can be selected. 
		It also creates the temporary file location**/
	function updateTemplate(){
		var inputChecked = "";
		var sourceChecked = "";
		var scaleChecked = "";
		
		// Get the selections for each of the three radio button groups. 
		$("input:radio:checked").each(function(i){
			if(this.name == "gstreamer-input") {
				inputChecked = this.value;
			} else if (this.name == "gstreamer-sources"){
				sourceChecked = this.value;
			} else if (this.name == "gstreamer-scale") {
				scaleChecked = this.value;
			}
		});
		
		// Select the correct demuxer and decoder based on the input radio buttons. 
		var vgaInput = "";
		var cameraInput = "";
		if(inputChecked == "decodebin") {
			vgaInput = vgaDecodebin;
			cameraInput = cameraDecodebin;
		} else if(inputChecked == "mpegps") {
			vgaInput = vgaMpegPS;
			cameraInput = cameraMpegPS;
		} else if(inputChecked == "mpegts") {
			vgaInput = vgaMpegTS;
			cameraInput = cameraMpegTS;
		} else if(inputChecked == "x264") {
			vgaInput = vgaMp4x264;
			cameraInput = cameraMp4x264;
		} else {
			vgaInput = vgaDecodebin;
			cameraInput = cameraDecodebin;
		}
		
		// Select the correct template for either using Camera, VGA and Audio or just VGA and Audio
		var template = "";
		if(sourceChecked == "CameraScreenAudio") {
			template = cameraScreenAudioTemplate;
		} else if(sourceChecked == "ScreenAudio") {
			template = screenAudioTemplate;
		} else {
			template = screenAudioTemplate;
		}
		
		// Select the correct scaling for the output video. 
		var scale = "";
		if(scaleChecked == "Original") {
			scale = original;
		} else if(scaleChecked == "Mobile") {
			scale = mobile;
		} else if(scaleChecked == "Tablet") {
			scale = tablet;
		}else if(scaleChecked == "HD") {
			scale = hd;
		}else if(scaleChecked == "FullHD") {
			scale = fullhd;
		} else {
			scale = original;
		}
		
		// Generate the output file including title, Sources, Scaling and workflow id.  
		// e.g. CHEM-250-02-201201-MWF-0830_1_CameraScreenAudio_FullHDScaled_28.mp4
		outputFile = "/tmp/" + title.replace(" ", "_") + "_" + sourceChecked + "_" + scaleChecked + "Scaled_" + id + ".mp4";	
		$("#gstreamer-output-files").attr("value", outputFile);
		
		// Replace all selected values in the template. 
		var gstreamerCommand = template;
		gstreamerCommand = gstreamerCommand.replace("VgaDECODE", vgaInput);
		gstreamerCommand = gstreamerCommand.replace("CameraDECODE", cameraInput);
		gstreamerCommand = gstreamerCommand.replace("VIDEOSCALE", scale);
		gstreamerCommand = gstreamerCommand.replace("VGA", presentation);
		gstreamerCommand = gstreamerCommand.replace("CameraWIDTH", presenterWidth);
		gstreamerCommand = gstreamerCommand.replace("CAMERA", presenter);
		gstreamerCommand = gstreamerCommand.replace("AUDIO", audio);
		gstreamerCommand = gstreamerCommand.replace("OUTPUTFILE", outputFile);
		
		$("#gstreamer-line").attr("value", gstreamerCommand);
	}
	
	
	/**
	* Continues the Workflow
	*/
	function continueWorkflow(){
		postData["org.opencastproject.workflow.config.gstreamer"] = $("#gstreamer-line").val();
        postData["org.opencastproject.workflow.config.gstreamer.outputfiles"] = $("#gstreamer-output-files").val();
        postData["org.opencastproject.workflow.config.gstreamer.acl"] = $("#acl").val();
        parent.ocRecordings.continueWorkflow(postData);
      }
            
	function cancel(){
		window.parent.location.href = "/admin";
	}
</script>
</head>
  <body>
	  <div class="lectureInfo" style="">
	    <h2 id="info-title"></h2>
	    <h4 id="info-creator"></h4>
	    <h4 id="info-series"></h4>
	  </div>

    <div class="holdStateUI" style="height: 100%; width: 100%;">
      <h1>Export Media</h1>
      <h3>Video Input Type</h3>
      <ul>
	      <li>
	      	<Input type = radio Name = gstreamer-input Value = "decodebin">
	      	Automatic (decodebin2)
	      </li>
	      <li>
	      	<Input type = radio Name = gstreamer-input Value = "mpegps" checked>
	      	MPEG 2 Program Stream (Default for capture agent, mpegpsdemux ! mpeg2dec)
	      </li>
	      <li>
	      	<Input type = radio Name = gstreamer-input Value = "mpegts">
	      	MPEG 2 Transport Stream (Mpeg2 from another source, mpegtsdemux ! mpeg2dec)
	      </li>
	      <li>
	      	<Input type = radio Name = gstreamer-input Value = "x264">
	      	H.264 AVC (x264 or H.264 in a mp4 or mov container, qtdemux ! ffdec_h264)
	      </li>
	  </ul>
      <h3>Sources</h3>
      <ul>
       <li>
	      	<Input type = radio Name = gstreamer-sources Value = "CameraScreenAudio">
	      	Camera, Screen and Audio
	      </li>
	      <li>
	      	<Input type = radio Name = gstreamer-sources Value = "ScreenAudio" checked>
	      	Screen and Audio
	      </li>
      </ul>
      <h3>Output Scale</h3>
      <ul>
          <li>
            <Input type = radio Name = gstreamer-scale Value = "Original" checked>
	      	Original Resolution
          </li>
	      <li>
	      	<Input type = radio Name = gstreamer-scale Value = "Mobile">
	      	Mobile (Scaled to 640 x 480)
	      </li>
	      <li>
	      	<Input type = radio Name = gstreamer-scale Value = "Tablet">
	      	Tablet (Scaled to 1024 x 768)
	      </li>
	      <li>
	      	<Input type = radio Name = gstreamer-scale Value = "HD">
	      	Scaled to HD (720p, 1280x720)
	      </li>
	      <li>
	      	<Input type = radio Name = gstreamer-scale Value = "FullHD">
	      	Scaled to Full HD (1080p, 1920x1080p)
	      </li>
	  </ul>
      <br>
      <h3>Roles able to see output videos (e.g. ROLE_ADMIN, ROLE_USER, ROLE_ANONYMOUS)</h3>
      Enter each role with its own tags e.g. &lt;roles&gt;&lt;role&gt;ROLE_ADMIN&lt;/role&gt; &lt;role&gt;ROLE_USER&lt;/role&gt; &lt;role&gt;ROLE_ANONYMOUS&lt;/role&gt;&lt;/roles&gt;
      <textarea id="acl" style="width: 100%; height: 5%;" wrap="hard" ></textarea>
      <br>
      <h3>gstreamer Command (enter without gst-launch e.g. fakesrc ! fakesink)</h3>
      Enter Gstreamer Line without gst-launch e.g. fakesrc ! fakesink
      <textarea id="gstreamer-line" style="width: 100%; height: 10%;" wrap="hard" ></textarea>
      <br>
      <h3>Temporary Output Files Paths (e.g./tmp/file1,/tmp/file2,/tmp/file3)</h3>
      Enter output filesnames (with paths) e.g. /tmp/test.mp4 and it will be added to the export download location.
      <textarea id="gstreamer-output-files" style="width: 100%; height: 5%;"></textarea>
      <div style="height: 100%; width: 100%; display: none;">
        <div id="source-frames" class="droppable-area" style="height: 100%; width: 20%; float: left;">
        </div>
        <div id="layout-area" class="droppable-area" style="height: 100%; width: 80%; float: left; border: 1px solid">
        </div>
      </div>

      <div id="actions">
        <input title="Continue processing this template" style="margin-left: 65px; margin-right: 16px; width: 160px;" onclick="continueWorkflow();" id="continueBtn" type="button" class="ui-button ui-corner-all" value="Continue processing" />
        <!-- a id="edit-link" class="secondaryButton">Edit metadata, then continue</a -->
        <a onclick="cancel()" title="Cancel" class="secondaryButton">Cancel</a>
      </div>
    </div>
  </body>
</html>
