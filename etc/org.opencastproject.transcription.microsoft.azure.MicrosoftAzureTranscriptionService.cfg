enabled = true

# List of supported languages: https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=stt#supported-languages:
language = en-US

# A list of language codes. The Azure language auto detection will pick it's detected language from one of these.
# The language auto detection cannot detect any languages not specified in this list.
# The list needs to have at least one element and can have at most four elements.
# To disable this feature, comment this property out or leave the value empty.
# List of supported languages: https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=language-identification
# Example: en-US,de-DE,fr-FR,it-IT
# Default: None
auto.detect.languages = en-US, de-DE

# Workflow to be executed when results are ready to be attached to media package.
# Default: microsoft-azure-attach-transcription
#workflow = microsoft-azure-attach-transcription

azure_storage_account_name = mmssubtitlestorage

# Azure storage container name.
# Leave this configuration value empty to generate container name.
azure_container_name = opencast-transcriptions

azure_account_access_key = secrete_microsoft_azure_storage_account_access_key

# Optional storage blob parent folder path inside of container
azure_blob_path = transcriptions

azure_speech_services_endpoint = https://speech.cognitiveservices.azure.com

azure_cognitive_services_subscription_key = secrete_azure_cognitive_services_subscription_key

azure_speech_recognition_min_confidence = 1

split.text.line.length = 100

# Generated transcription file format, can be srt or vtt.
# Default: vtt
output.file.format = vtt