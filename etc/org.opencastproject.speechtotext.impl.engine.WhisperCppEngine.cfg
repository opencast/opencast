# Configuration for setting a custom path to the Whisper command line tool
# Default: whisper
#whispercpp.root.path=whispercpp

# Absolute path to language model
# RPMs install models to /usr/share/ggml/ggml-<model>.bin
# Available models: tiny, base, small, medium, large.
# Default: /usr/share/ggml/ggml-base.bin
#whispercpp.model=/usr/share/ggml/ggml-base.bin


## Optional settings to configure the underlying whispercpp engine

# Beam size for beam search
#whispercpp.beam-size=-1

# Maximum segment length in characters
#whispercpp.max-len=0

# Number of threads to use during computation
#whispercpp.threads=4

# Number of processors to use during computation
#whispercpp.processors=1

# Maximum number of text context tokens to store
#whispercpp.max-context=-1

# Split on word rather than on token
#whispercpp.split-on-word=false

# Number of best candidates to keep
#whispercpp.best-of=2

# Word timestamp probability threshold
#whispercpp.word-thold=0.01

# Entropy threshold for decoder fail
#whispercpp.entropy-thold=2.40

# Log probability threshold for decoder fail
#whispercpp.logprob-thold=-1.00

# Stereo audio diarization
#whispercpp.diarize=false

# Enable tinydiarize (requires a tdrz model)
#whispercpp.tinydiarize=false

# Do not use temperature fallback while decoding
#whispercpp.no-fallback=false